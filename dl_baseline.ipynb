{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ9i64vMTCRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFGViEdjTQyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "drive.mount('/content/drive')\n",
        "repo_path = \"/content/fpl_prediction/\"\n",
        "if not os.path.isdir(repo_path):\n",
        "  !git clone https://github.com/SolomonAduolMaina/fpl_prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fhMiyDBAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIELDS = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'goals_conceded', 'goals_scored', 'ict_index', 'influence', 'minutes', 'opponent_team', 'own_goals', 'penalties_missed', 'penalties_saved', 'player', 'red_cards', 'round', 'saves', 'selected', 'team_a_score', 'team_h_score', 'threat',  'total_points', 'transfers_balance', 'transfers_in', 'transfers_out', 'value', 'was_home', 'yellow_cards']\n",
        "\n",
        "def get_players_data(SEASON, ROUND):\n",
        "  SEASON = { 2016 : 0, 2017 : 1, 2018 : 2, 2019 : 3 }[SEASON]\n",
        "  actual = 38 * SEASON + ROUND - 1\n",
        "  SEASON = actual // 38 + 1\n",
        "  ROUND = actual % 38\n",
        "  if ROUND == 0 and SEASON > 1:\n",
        "    ROUND = 38\n",
        "    SEASON = SEASON - 1\n",
        "  \n",
        "  directory_string = '/content/fpl_prediction/data/20{0}-{1}/players/'\n",
        "  players_data = {}\n",
        "  players = {}\n",
        "  index_count = 0\n",
        "\n",
        "  for season in range(0, SEASON):\n",
        "      formatted_string = directory_string.format(season + 16, season + 16 + 1)\n",
        "      directory = os.fsencode(formatted_string)\n",
        "\n",
        "      for file in os.listdir(directory):\n",
        "          filename = os.fsdecode(file)\n",
        "          name = \" \".join(filename.split('_')[:2])\n",
        "\n",
        "          if name not in players:\n",
        "              players[name] = index_count\n",
        "              index_count = index_count + 1\n",
        "\n",
        "          csv = pd.read_csv(formatted_string + filename + '/gw.csv', encoding = \"UTF-8\")\n",
        "          csv = csv[csv['round'] <= ROUND] if season == SEASON - 1 else csv\n",
        "          csv['round'] = 38 * season + csv['round']\n",
        "          csv['player'] = pd.Series([players[name]] * len(csv))\n",
        "          csv = csv[FIELDS]\n",
        "          csv = csv.astype('float')\n",
        "\n",
        "          if name not in players_data:\n",
        "              players_data[name] = csv\n",
        "          else:\n",
        "              players_data[name] = pd.concat([players_data[name], csv])\n",
        "\n",
        "  players_data = { name : df.drop_duplicates(subset=['round'], keep='last') for (name,df)  in players_data.items() if len(players_data[name]) > 0}\n",
        "\n",
        "  return players_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwSBVQb_0imJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gameweek_data(SEASON, ROUND):\n",
        "\n",
        "  SEASON = { 2016 : 0, 2017 : 1, 2018 : 2, 2019 : 3 }[SEASON]  \n",
        "  directory_string = '/content/fpl_prediction/data/20{0}-{1}/players/'\n",
        "  players_data = {}\n",
        "  fields = ['round', 'value', 'total_points']\n",
        "\n",
        "  formatted_string = directory_string.format(SEASON + 16, SEASON + 16 + 1)\n",
        "  directory = os.fsencode(formatted_string)\n",
        "  for file in os.listdir(directory):\n",
        "      filename = os.fsdecode(file)\n",
        "      name = \" \".join(filename.split('_')[:2])\n",
        "\n",
        "      csv = pd.read_csv(formatted_string + filename + '/gw.csv', encoding = \"UTF-8\")\n",
        "      csv = csv[csv['round'] == ROUND]\n",
        "      csv = csv[fields]\n",
        "      csv = csv.astype('float')\n",
        "      players_data[name] = csv\n",
        "  \n",
        "  players_data = { name : df.drop_duplicates(subset=['round'], keep='last') for (name,df) in players_data.items() if len(players_data[name]) > 0}\n",
        "\n",
        "  name_mapping = {}\n",
        "  player_mapping = pd.read_csv('/content/fpl_prediction/name_conversions.csv', encoding = \"UTF-8\")\n",
        "  for row in player_mapping.itertuples():\n",
        "      name_mapping[row.bad_name] = row.good_name\n",
        "\n",
        "  directory_string = '/content/fpl_prediction/data/20{0}-{1}/'\n",
        "  formatted_string = directory_string.format(SEASON + 16, SEASON + 16 + 1)\n",
        "  positions_and_teams={}\n",
        "  csv = pd.read_csv(formatted_string + 'players_raw.csv', encoding = \"UTF-8\")\n",
        "  for row in csv.itertuples():\n",
        "      name = row.first_name + ' ' + row.second_name\n",
        "      name = name_mapping[name] if name in name_mapping else name\n",
        "      position = row.element_type\n",
        "      team_id = row.team_code\n",
        "      positions_and_teams[name] = (position, team_id)\n",
        "\n",
        "  gameweek_data = pd.DataFrame(columns=['name', 'team', 'position', 'value', 'total_points'])\n",
        "  for name in players_data:\n",
        "    convenient_round = int(players_data[name]['round']) - 1\n",
        "    position = positions_and_teams[name][0]\n",
        "    team = positions_and_teams[name][1]\n",
        "    value = players_data[name]['value']\n",
        "    total_points = players_data[name]['total_points']\n",
        "    data = {'name' : name, 'team' : team, 'position' : position, 'value': value, 'total_points' : total_points}\n",
        "    gameweek_data = gameweek_data.append(data, ignore_index=True)\n",
        "\n",
        "  return gameweek_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T4C1DRkasnJB",
        "colab": {}
      },
      "source": [
        "class PlayerDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, players_data, batch_size, embedding_dim):\n",
        "    self.sorted_names = list(players_data)\n",
        "    self.sorted_names.sort()\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    all_data = pd.concat([players_data[name] for name in self.sorted_names])\n",
        "    all_features = all_data.drop(['total_points'], axis=1).to_numpy()\n",
        "    all_total_points = all_data.drop(all_data.columns.difference(['total_points']), axis=1).to_numpy()\n",
        "    scaler = preprocessing.RobustScaler()\n",
        "    scaled_features = scaler.fit_transform(all_features)\n",
        "\n",
        "    self.players_data = {}\n",
        "    training_data = []\n",
        "    end = 0\n",
        "\n",
        "    for name in self.sorted_names:\n",
        "      history_length = len(players_data[name])\n",
        "\n",
        "      for length in range(history_length - 1): # -1 because we have no prediction for the last point\n",
        "        training_data.append((torch.Tensor(scaled_features[end : end + 1 + length, :]), all_total_points[end + length + 1]))\n",
        "\n",
        "      new_end = end + history_length\n",
        "      features = torch.Tensor(scaled_features[end : new_end, :])\n",
        "      total_points = torch.Tensor(all_total_points[end : new_end, :])\n",
        "      self.players_data[name] = (features, total_points)\n",
        "      end = new_end\n",
        "\n",
        "    random.shuffle(training_data)\n",
        "    num_batches = len(training_data) // self.batch_size\n",
        "    batches = [(k * self.batch_size, (k + 1) * self.batch_size) for k in range(num_batches)]\n",
        "    batches.append((num_batches * self.batch_size, len(training_data)))\n",
        "\n",
        "    self.batched_data = []\n",
        "    for (start, end) in batches:\n",
        "      if start != end:\n",
        "        lengths = [len(features) for (features, _) in training_data[start : end]]\n",
        "        length = end - start\n",
        "        three_d = torch.zeros((max(lengths), length, self.embedding_dim))\n",
        "\n",
        "        total_points = []\n",
        "        for index in range(start, end):\n",
        "          features, points = training_data[index]\n",
        "          three_d[: features.shape[0], index - start, : features.shape[1]] = features\n",
        "          total_points.append(points)\n",
        "\n",
        "        self.batched_data.append((three_d, torch.FloatTensor(lengths), torch.FloatTensor(total_points)))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.batched_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.batched_data[index]\n",
        "    \n",
        "  def player_data(self, name):\n",
        "    return self.players_data[name]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sjNLdMNvAV_s",
        "colab": {}
      },
      "source": [
        "class GRUPredictor(torch.nn.Module):\n",
        " \n",
        "  def __init__(self, embedding_dim, hidden_dim):\n",
        "    super(GRUPredictor, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "  def forward(self, features, lengths):\n",
        "    packed_features = torch.nn.utils.rnn.pack_padded_sequence(features, lengths, enforce_sorted=False)\n",
        "    _, hidden = self.gru(packed_features) # maybe use output for attention later\n",
        "    return self.fc(hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyaT5KdAkbSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "EMBEDDING_DIM = len(FIELDS) - 1\n",
        "model = GRUPredictor(embedding_dim, HIDDEN_DIM).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "EPOCHS = 100\n",
        "SEASON = 2017\n",
        "ROUND = 2\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "players_data = get_players_data(SEASON, ROUND)\n",
        "gameweek_data = get_gameweek_data(SEASON, ROUND)\n",
        "train_dataset = PlayerDataset(players_data, BATCH_SIZE=128, embedding_dim=len(FIELDS) - 1)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WI2oj6hdGc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = []\n",
        "for epoch in range(100000):\n",
        "  running_loss = 0.0\n",
        "  items = 0\n",
        "\n",
        "  for index, (features, lengths, points) in enumerate(train_dataloader):\n",
        "    features = features.squeeze(0).to(device)\n",
        "    lengths = lengths.view(-1).to(device)\n",
        "    points = points.view(-1).to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "    pred = model(features, lengths).view(-1)\n",
        "    loss = criterion(pred, points)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    items = items + 1\n",
        "  \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    avg_loss = running_loss / items\n",
        "    print('Epoch {0}: average loss {1}'.format(epoch + 1, running_loss / items))\n",
        "    graph.append(avg_loss)\n",
        "\n",
        "PATH = '/content/drive/My Drive/CIS 522/CIS-522-project/gru-{0}-{1}-{2}-{3}-{4}.pt'.format(SEASON, ROUND, BATCH_SIZE, HIDDEN_DIM, EPOCHS)\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7OstNkcMA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(graph)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}