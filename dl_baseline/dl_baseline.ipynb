{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dl_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI1YzqyEUznL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This notebook has two functions of note, predict and compute score:\n",
        "\n",
        "(squad, candidates, captain, vice_captain, priorities) = predict(2019, 1)\n",
        "compute_score(squad, candidates, captain, vice_captain, priorities, 2019, 1)\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Roxco1Omd1Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_DIM, BATCH_SIZE, EPOCHS, LR, EMBEDDING_DIM, SEASON = 512, 512, 100, 1e-3, len(FIELDS) - 1, 2019\n",
        "actual_scores, max_scores, single_week_scores = {}, {}, {}\n",
        "previous_previous_squad, previous_squad, squad, saved_transfer = [], [], [], False\n",
        "\n",
        "for ROUND in range(1, 30):\n",
        "  SAVE_DIR = '/content/drive/My Drive/CIS 522/CIS-522-project/2019'\n",
        "  save_path = '{0}/gru-{1}-{2}-{3}-{4}-{5}-{6}.pt'.format(SAVE_DIR, SEASON, ROUND, BATCH_SIZE, HIDDEN_DIM, EPOCHS, LR)\n",
        "  model = GRUPredictor(EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "  model.load_state_dict(torch.load(save_path, map_location=torch.device('cpu') ))\n",
        "  model.eval()\n",
        "\n",
        "  previous_previous_squad = previous_squad\n",
        "  previous_squad = squad\n",
        "  if len(previous_previous_squad) > 0 and len(previous_squad) > 0:\n",
        "    num_transfers = len(set(previous_squad) - set(squad))\n",
        "    saved_transfer = (num_transfers == 0) or (num_transfers == 1 and saved_transfer)\n",
        "\n",
        "  (squad, candidates, captain, vice_captain, priorities) = \\\n",
        "  predict(SEASON, ROUND, model, previous_squad, saved_transfer)\n",
        "  actual_score = compute_score(squad, candidates, captain, vice_captain, priorities, \n",
        "                  SEASON, ROUND, previous_squad, saved_transfer)\n",
        "  actual_scores[ROUND] = actual_score\n",
        "  (squad, candidates, captain, vice_captain, priorities) = best_gameweek_team(SEASON, ROUND)\n",
        "  max_score = compute_score(squad, candidates, captain, vice_captain, priorities, SEASON, ROUND)\n",
        "  max_scores[ROUND] = max_score\n",
        "  (squad, candidates, captain, vice_captain, priorities) = predict(SEASON, ROUND, model=model)\n",
        "  single_week_score = compute_score(squad, candidates, captain, vice_captain, priorities, SEASON, ROUND)\n",
        "  single_week_scores[ROUND] = single_week_score\n",
        "\n",
        "  print('Max: {0}, Single: {1}, Actual: {2}'.format(max_score, single_week_score, actual_score))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ9i64vMTCRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pulp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import pulp\n",
        "import sys\n",
        "from functools import cmp_to_key\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "drive.mount('./drive')\n",
        "repo_path = \"./fpl_prediction/\"\n",
        "if not os.path.isdir(repo_path):\n",
        "  !git clone --recurse-submodules https://github.com/SolomonAduolMaina/fpl_prediction\n",
        "\n",
        "%load_ext tensorboard\n",
        "DRIVE_DIR = \"./drive/My Drive/CIS 522/CIS-522-project/\"\n",
        "ROOT_LOG_DIR = DRIVE_DIR + \"logs/\"\n",
        "%tensorboard --logdir {ROOT_LOG_DIR.replace(\" \", \"\\\\ \")}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rFjlmsZENe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Evaluates to (squad, candidates, captain, vice_captain) picked by model + optimization\n",
        "to play in season SEASON and round ROUND, assuming that the squad from last week is\n",
        "previous_squad, the squad from two_weeks ago is previous_previous_squad, and saved_transfer is\n",
        "True if you have a saved transfer.\n",
        "\"\"\"\n",
        "def predict(SEASON, ROUND, model=None, previous_squad=[], saved_transer=False):\n",
        "  HIDDEN_DIM, BATCH_SIZE, EPOCHS, LR, EMBEDDING_DIM = 512, 512, 100, 1e-3, len(FIELDS) - 1\n",
        "\n",
        "  name_mapping = name_conversions()\n",
        "  season, previous_week = (SEASON, ROUND - 1) if ROUND > 1 else (max([2016, SEASON - 1]), 38)\n",
        "  players_data = get_players_data(season, previous_week, name_mapping)\n",
        "  train_dataset = PlayerDataset(players_data, batch_size=BATCH_SIZE, embedding_dim=EMBEDDING_DIM)\n",
        "  train_dataloader = torch.utils.data.DataLoader(train_dataset, shuffle=True)\n",
        "\n",
        "  if model is None:\n",
        "    model = GRUPredictor(EMBEDDING_DIM, HIDDEN_DIM).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), LR)\n",
        "    criterion = nn.MSELoss()\n",
        "    log_path = '{0}/gru-{1}-{2}-{3}-{4}-{5}-{6}'.format(ROOT_LOG_DIR, SEASON, ROUND, BATCH_SIZE, HIDDEN_DIM, EPOCHS, LR)\n",
        "    SAVE_DIR = '/content/drive/My Drive/CIS 522/CIS-522-project/2019'\n",
        "    save_path = '{0}/gru-{1}-{2}-{3}-{4}-{5}-{6}.pt'.format(SAVE_DIR, SEASON, ROUND, BATCH_SIZE, HIDDEN_DIM, EPOCHS, LR)\n",
        "    train_model(model, optimizer, criterion, train_dataloader, EPOCHS, log=True, save=True, log_path=log_path, save_path=save_path)\n",
        "\n",
        "  ps_and_ts = positions_and_teams(SEASON, name_mapping)\n",
        "  values = get_gameweek_data(SEASON, ROUND, ps_and_ts, name_mapping) # Are player values posted here before the deadline?\n",
        "  \n",
        "  rankings = {}\n",
        "  for name in ps_and_ts: # All players registered this season\n",
        "    position, team = ps_and_ts[name]\n",
        "    value = 1001 if name not in values else values[name]['value'] # Optimizer excludes this player\n",
        "\n",
        "    prediction = 0 # I prefer for this to be -infinity but pulp refuses to solve such\n",
        "    if name in players_data:\n",
        "      history = train_dataset.player_data(name).to(device)\n",
        "      length = history.shape[0]\n",
        "      prediction = model(history.view(length, 1, EMBEDDING_DIM), [length]).view(-1)\n",
        "      \n",
        "    data = { 'team' : team, 'position' : position, 'value': value, 'total_points' : prediction }\n",
        "    rankings[name] = data\n",
        "\n",
        "  (name_mapping, fifteen) = optimize(rankings, previous_squad, saved_transfer, cost=12) # magic number\n",
        "  (squad, candidates, captain, vice_captain) = pick_team(rankings, name_mapping, fifteen, ps_and_ts)\n",
        "\n",
        "  priorities = {}\n",
        "  for player in set(squad):\n",
        "    priorities[player] = float(rankings[player]['total_points'])\n",
        "\n",
        "  return (squad, candidates, captain, vice_captain, priorities)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to (squad, candidates, captain, vice_captain) given predictions, which\n",
        "is a dictionary whose keys are player_names and whose values contain the expected\n",
        "points of the player, name_mapping which maps from the names of the linear programming variables in fifteen\n",
        "to player_names - these two are expected to be the output of optimize - and \n",
        "positions_and_teams is expected to be the output of positions_and_teams.\n",
        "\"\"\"\n",
        "def pick_team(predictions, name_mapping, fifteen, positions_and_teams):\n",
        "  squad = set([name_mapping[v.name] for v in fifteen if v.varValue != 0])\n",
        "  required = [1, 3, 0, 1]\n",
        "  squad_positions = { 1 : [], 2 : [], 3 : [], 4 : [] }\n",
        "\n",
        "  # Rank players in each position\n",
        "  for player in squad:\n",
        "      squad_positions[positions_and_teams[player][0]].append((player, predictions[player]['total_points']))\n",
        "  for position in squad_positions:\n",
        "      squad_positions[position] = sorted(squad_positions[position], key=cmp_to_key(lambda x, y: x[1] - y[1]), reverse=True)\n",
        "\n",
        "  # Fill positions that need filling\n",
        "  candidates = []\n",
        "  for position in squad_positions:\n",
        "    needed = required[position - 1]\n",
        "    candidates += squad_positions[position][:needed]\n",
        "    squad_positions[position] = squad_positions[position][needed:]\n",
        "\n",
        "  # Fill remaining spots\n",
        "  remaining = []\n",
        "  for position in squad_positions:\n",
        "    if not position == 1: # We've already picked a goalkeeper\n",
        "      remaining += squad_positions[position]\n",
        "  remaining = sorted(remaining, key=cmp_to_key(lambda x, y: x[1] - y[1]), reverse=True)\n",
        "  playing_size = len(set(candidates))\n",
        "\n",
        "  while playing_size < 11 :\n",
        "    candidates.append(remaining.pop(0))\n",
        "    playing_size += 1\n",
        "  \n",
        "  # Pick captain and vice captain\n",
        "  candidates = sorted(candidates, key=cmp_to_key(lambda x, y: x[1] - y[1]), reverse=True)\n",
        "  captain = candidates[0][0]\n",
        "  vice_captain = candidates[1][0]\n",
        "  candidates = set([ player for (player, _) in candidates ])\n",
        "\n",
        "  return (squad, set(candidates), captain, vice_captain)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to a number > 1 if x played and y didn't, or if they both\n",
        "played or didn't play but x is ranked higher than y. Otherwise evaluates\n",
        "to -1.\n",
        "\"\"\"\n",
        "def play_priority_sort(x, y):\n",
        "  (_, played1, points1), (_, played2, points2) = x, y\n",
        "  if played1 and not played2: return 1\n",
        "  if played2 and not played1: return -1\n",
        "  return points1 - points2\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to True if player played in the gameweek whose results are reflected in\n",
        "gameweek_data. Otherwise evaluates to True.\n",
        "\"\"\"\n",
        "def played(player, gameweek_data):\n",
        "  return gameweek_data[player]['minutes'] > 0 or \\\n",
        "        gameweek_data[player]['yellow_cards'] > 0 or \\\n",
        "        gameweek_data[player]['red_cards'] > 0\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to a number, the score for the team scored, captain's scored is doubled if they played,\n",
        "otherwise vice_captain's score is doubled. If the transfers from previous_squad to squad\n",
        "number to more than 1, subtract 4 * that number -1, since everyone gets one free transfer\n",
        "per week. Also add 4 back if saved transfer is True in this case.\n",
        "\"\"\"\n",
        "def compute_score(squad, candidates, captain, vice_captain, priorities, \n",
        "                  SEASON, ROUND, previous_squad=[], saved_transfer=False):\n",
        "  name_mapping = name_conversions()\n",
        "  ps_and_ts = positions_and_teams(SEASON, name_mapping)\n",
        "  gameweek_data = get_gameweek_data(SEASON, ROUND, ps_and_ts, name_mapping)\n",
        "  scored = team_scored(squad, candidates, priorities, gameweek_data)\n",
        "  \n",
        "  points_earned = 0\n",
        "  for player in scored:\n",
        "      points_earned += gameweek_data[player]['total_points']\n",
        "\n",
        "  if played(captain, gameweek_data):\n",
        "    points_earned += gameweek_data[captain]['total_points']\n",
        "  elif played(vice_captain, gameweek_data):\n",
        "    points_earned += gameweek_data[vice_captain]['total_points']\n",
        "\n",
        "  if len(previous_squad) == 0:\n",
        "    return points_earned\n",
        "\n",
        "  num_transfers = len(set(previous_squad) - set(squad))\n",
        "  saved_transfer = (num_transfers == 0) or (num_transfers == 1 and saved_transfer)\n",
        "\n",
        "  if num_transfers <= 1:\n",
        "    return points_earned\n",
        "  return points_earned - (4 * (num_transfers - (1 if saved_transfer else 0) - 1)) # -1 for free transfer\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to an iterable of the team that actually played given squad of 15 and 11 candidates.\n",
        "Some players might have to be substituted if they didn't play according to gameweek_data.\n",
        "In this case use rankings[player]['total_points'] as substitution priorities.\n",
        "\"\"\"\n",
        "def team_scored(squad, candidates, priorities, gameweek_data):\n",
        "  playing = [ player for player in candidates if played(player, gameweek_data) ]\n",
        "\n",
        "  playing_size = len(set(playing))\n",
        "  if playing_size < 11:\n",
        "    # We'll play remaining in ascending order of their priorities\n",
        "    squad = set(squad)\n",
        "    dropped = set(candidates) - set(playing)\n",
        "    substitutes = set(squad) - set(candidates)\n",
        "\n",
        "    # Rank players according to their position\n",
        "    remaining = { 1 : [], 2 : [], 3 : [], 4 : []}\n",
        "    for player in (dropped.union(substitutes)):\n",
        "      remaining[gameweek_data[player]['position']].append((player, played(player, gameweek_data), priorities[player]))\n",
        "    for position in remaining:\n",
        "      remaining[position] = sorted(remaining[position], key=cmp_to_key(play_priority_sort), reverse=True)\n",
        "\n",
        "    # Compute the positions that need to be filled\n",
        "    positions = [0, 0, 0, 0] # Goalkeeper, Defenders, Midfielders, Strikers\n",
        "    for name in playing:\n",
        "      positions[int(gameweek_data[name]['position']) - 1] += 1\n",
        "    to_fill = [max(0, 1 - positions[0]), max(0, 3 - positions[1]), 0, max(0, 1 - positions[3])]\n",
        "\n",
        "    # Fill the positions that need to be filled\n",
        "    for position in range(len(positions)):\n",
        "      still_need = to_fill[position]\n",
        "      playing += [ player for (player, _, _) in remaining[position + 1][:still_need] ]\n",
        "      remaining[position + 1] = remaining[position + 1][still_need:] if position != 0 else [] # Keeper already picked\n",
        "    \n",
        "    playing_size = len(set(playing))\n",
        "    if playing_size < 11 : # Add remaining in ascending order till done\n",
        "      last_batch = []\n",
        "      for position in remaining:\n",
        "        last_batch += remaining[position]\n",
        "      last_batch = sorted(last_batch, key=cmp_to_key(lambda x, y: x[1] - y[1]), reverse=True)\n",
        "\n",
        "      while playing_size < 11 :\n",
        "        playing.append(last_batch.pop(0)[0])\n",
        "        playing_size += 1\n",
        "\n",
        "      \"\"\"This is sufficient since if no more played the highest priority ones will\n",
        "        be chosen, and these were candidates to begin with.\"\"\"\n",
        "\n",
        "  return set(playing)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to (squad, candidates, captain, vice_captain, priorities) for the best team\n",
        "in season SEASON and round ROUND.\n",
        "\"\"\"\n",
        "def best_gameweek_team(SEASON, ROUND):\n",
        "  name_mapping = name_conversions()\n",
        "  ps_and_ts = positions_and_teams(SEASON, name_mapping)\n",
        "  rankings = get_gameweek_data(SEASON, ROUND, ps_and_ts, name_mapping)\n",
        "  (name_mapping, fifteen) = optimize(rankings)\n",
        "  (squad, candidates, captain, vice_captain) = pick_team(rankings, name_mapping, fifteen, ps_and_ts)\n",
        "\n",
        "  priorities = {}\n",
        "  for player in set(squad):\n",
        "    priorities[player] = float(rankings[player]['total_points'])\n",
        "\n",
        "  return (squad, candidates, captain, vice_captain, priorities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2Lh2YKfCN93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Evaluates to (name_mapping, fifteen) where fifteen is the the set of all linear programming variables. \n",
        "optimized using predictions, assuming that last week's squad was previous_squad and\n",
        "saved_transfer is True if we have a saved transfer at this point. cost will be optimized\n",
        "away. name_mapping maps the name of each linear programming variable to the player associated\n",
        "to that variable.\n",
        "\n",
        "NOTE: We do not optimize for the eleven as this causes a maximum recursion depth error.\n",
        "I believe there are just too many variables if we solve for that. But the problems are reasonably\n",
        "similar.\n",
        "\"\"\"\n",
        "def optimize(predictions, previous_squad=[], saved_transfer=False, cost=0):\n",
        "  fifteen = { name : (pulp.LpVariable(name, lowBound=0, upBound=1, cat=\"Integer\"), name) for name in predictions }\n",
        "  goal_keepers = { name : fifteen[name][0] for name in predictions if predictions[name]['position'] == 1}\n",
        "  defenders = { name : fifteen[name][0] for name in predictions if predictions[name]['position'] == 2}\n",
        "  mid_fielders = { name: fifteen[name][0] for name in predictions if predictions[name]['position'] == 3}\n",
        "  strikers = { name : fifteen[name][0] for name in predictions if predictions[name]['position'] == 4}\n",
        "\n",
        "  model = pulp.LpProblem(\"Fantasy Premier League\", pulp.LpMaximize)\n",
        "\n",
        "  # 2 Goalkeepers, 5 defenders, 5 mid_fields, 5 strikers in whole squad\n",
        "  model += pulp.lpSum( [goal_keepers[name] for name in goal_keepers] ) == 2\n",
        "  model += pulp.lpSum( [defenders[name] for name in defenders] ) == 5\n",
        "  model += pulp.lpSum( [mid_fielders[name] for name in mid_fielders] ) == 5\n",
        "  model += pulp.lpSum( [strikers[name] for name in strikers] ) == 3\n",
        "\n",
        "  # Cost Cap\n",
        "  model += pulp.lpSum( [fifteen[name][0] * predictions[name]['value'] for name in predictions] ) <= 1000\n",
        "\n",
        "  # Only three players in the squad per team\n",
        "  for team in set([predictions[name]['team'] for name in predictions]):\n",
        "      team_members = { name : fifteen[name][0] for name in predictions if int(predictions[name]['team']) == int(team)}\n",
        "      model += pulp.lpSum( [team_members[name] for name in team_members] ) <= 3\n",
        "    \n",
        "  # Maximize the squad score minus the transfer penalty. Can we do anything about the free transfer?\n",
        "  model += pulp.lpSum( [fifteen[name][0] * predictions[name]['total_points'] for name in fifteen] ) \\\n",
        "          - (cost * pulp.lpSum( [fifteen[name][0] * (1 if name not in previous_squad else 0) for name in predictions] )) \\\n",
        "          + (cost if saved_transfer else 0)\n",
        "\n",
        "  model.solve()\n",
        "\n",
        "  name_mapping = { variable.name : name for (variable, name) in fifteen.values() }\n",
        "  fifteen = [variable for (variable, _) in fifteen.values()]\n",
        "\n",
        "  return (name_mapping, fifteen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WI2oj6hdGc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GRUPredictor(torch.nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim):\n",
        "    super(GRUPredictor, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.gru = nn.GRU(embedding_dim, hidden_dim)\n",
        "    self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "  def forward(self, features, lengths):\n",
        "    packed_features = torch.nn.utils.rnn.pack_padded_sequence(features, lengths, enforce_sorted=False)\n",
        "    _, hidden = self.gru(packed_features)\n",
        "    return self.fc(hidden)\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, criterion, train_dataloader, EPOCHS, log_path=\"\", save_path=\"\", save=False, log=False):\n",
        "  if log:\n",
        "    writer = SummaryWriter(log_path)\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "    running_loss = 0.0\n",
        "    items = 0\n",
        "\n",
        "    for index, (features, lengths, points) in enumerate(train_dataloader):\n",
        "      features = features.squeeze(0).to(device)\n",
        "      lengths = lengths.view(-1).to(device)\n",
        "      points = points.view(-1).to(device)\n",
        "\n",
        "      model.zero_grad()\n",
        "      pred = model(features, lengths).view(-1)\n",
        "      loss = criterion(pred, points)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      items = items + 1\n",
        "    \n",
        "    avg_loss = running_loss / items\n",
        "    if log:\n",
        "      print('Epoch {0}: average loss {1}'.format(epoch + 1, avg_loss))\n",
        "      writer.add_scalar(\"Loss\", avg_loss, epoch + 1)\n",
        "\n",
        "  if save:\n",
        "    torch.save(model.state_dict(), save_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0fhMiyDBAZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FIELDS = ['assists', 'bonus', 'bps', 'clean_sheets', 'creativity', 'goals_conceded', 'goals_scored', 'ict_index', 'influence', 'minutes', 'opponent_team', 'own_goals', 'penalties_missed', 'penalties_saved', 'player', 'red_cards', 'round', 'saves', 'selected', 'team_a_score', 'team_h_score', 'threat',  'total_points', 'transfers_balance', 'transfers_in', 'transfers_out', 'value', 'was_home', 'yellow_cards']\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Some players have different names at different points of the data\n",
        "e.g. Isaac Success and Isaac Success Ajayi. \n",
        "\n",
        "This function evaluates to a dictionary mapping different representations\n",
        "to a single representation using name_conversions.csv, which is manually generated.\n",
        "\"\"\"\n",
        "def name_conversions():\n",
        "  # Initialize the mapping of names in players_raw.csv that need to be translated\n",
        "  name_mapping = {}\n",
        "  player_mapping = pd.read_csv('./fpl_prediction/name_conversions.csv', encoding = \"UTF-8\")\n",
        "  for row in player_mapping.itertuples():\n",
        "      name_mapping[row.bad_name.lower()] = row.good_name.lower()\n",
        "  \n",
        "  return name_mapping\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to a dictionary whose keys are player names and whose values\n",
        "are the entire player's history up till season SEASON and round ROUND.\n",
        "name_mapping is expected to be the result of name_conversions.\n",
        "\"\"\"\n",
        "def get_players_data(SEASON, ROUND, name_mapping):\n",
        "  SEASON = { 2016 : 0, 2017 : 1, 2018 : 2, 2019 : 3 }[SEASON]\n",
        "  directory_string = './fpl_prediction/Fantasy-Premier-League/data/20{0}-{1}/players/'\n",
        "  players_data = {}\n",
        "  players = {}\n",
        "  index_count = 0\n",
        "\n",
        "  for season in range(SEASON + 1):\n",
        "      formatted_string = directory_string.format(season + 16, season + 16 + 1)\n",
        "      directory = os.fsencode(formatted_string)\n",
        "\n",
        "      for file in os.listdir(directory):\n",
        "          filename = os.fsdecode(file)\n",
        "          name = \" \".join(filename.split('_')[:2]).lower()\n",
        "          name = name_mapping[name] if name in name_mapping else name\n",
        "\n",
        "          if name not in players:\n",
        "              players[name] = index_count\n",
        "              index_count = index_count + 1\n",
        "\n",
        "          csv = pd.read_csv(formatted_string + filename + '/gw.csv', encoding = \"UTF-8\")\n",
        "          csv = csv[csv['round'] <= ROUND] if season == SEASON else csv\n",
        "          csv['round'] = 38 * season + csv['round']\n",
        "          csv['player'] = pd.Series([players[name]] * len(csv))\n",
        "          csv = csv[FIELDS]\n",
        "          csv = csv.astype('float')\n",
        "\n",
        "          if name not in players_data:\n",
        "              players_data[name] = csv\n",
        "          else:\n",
        "              players_data[name] = pd.concat([players_data[name], csv])\n",
        "\n",
        "  players_data = { name : df.drop_duplicates(subset=['round'], keep='last') for (name,df)  in players_data.items() if len(df) > 0}\n",
        "\n",
        "  return players_data\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to a dictionary whose keys are player names and whose values are\n",
        "pairs containing the player's position and team for the season SEASON. Ideally we\n",
        "would have these computed week-by-week but I don't think we have that data.\n",
        "name_mapping is expected to be the output of name_conversions.\n",
        "\"\"\"\n",
        "def positions_and_teams(SEASON, name_mapping):\n",
        "  SEASON = { 2016 : 0, 2017 : 1, 2018 : 2, 2019 : 3 }[SEASON]  \n",
        "  directory_string = './fpl_prediction/Fantasy-Premier-League/data/20{0}-{1}/'\n",
        "  formatted_string = directory_string.format(SEASON + 16, SEASON + 16 + 1)\n",
        "\n",
        "  result={}\n",
        "  csv = pd.read_csv(formatted_string + 'players_raw.csv', encoding = \"UTF-8\")\n",
        "  for row in csv.itertuples():\n",
        "      name = (row.first_name + ' ' + row.second_name).lower()\n",
        "      name = name_mapping[name] if name in name_mapping else name\n",
        "      position = row.element_type\n",
        "      team_id = row.team_code\n",
        "      result[name] = (position, team_id)\n",
        "    \n",
        "  return result\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Evaluates to a dictionary where the keys are the player names and the values\n",
        "are dictionaries mapping attributes used for optimization and computing\n",
        "team scores in gameweek ROUND of season SEASON. \n",
        "These attributes are ['round', 'value', 'total_points', 'minutes', 'yellow_cards', 'red_cards'].\n",
        "positions_and_teams is expected to be the output of positions_and_teams(SEASON, name_mapping)\n",
        "name_mapping is expected to be the output of name_conversions\n",
        "\"\"\"\n",
        "def get_gameweek_data(SEASON, ROUND, positions_and_teams, name_mapping):\n",
        "  SEASON = { 2016 : 0, 2017 : 1, 2018 : 2, 2019 : 3 }[SEASON]  \n",
        "  directory_string = './fpl_prediction/Fantasy-Premier-League/data/20{0}-{1}/players/'\n",
        "  players_data = {}\n",
        "  fields = ['round', 'value', 'total_points', 'minutes', 'yellow_cards', 'red_cards']\n",
        "\n",
        "  # Fetch each player's performance for round ROUND and season SEASON\n",
        "  formatted_string = directory_string.format(SEASON + 16, SEASON + 16 + 1)\n",
        "  directory = os.fsencode(formatted_string)\n",
        "  for file in os.listdir(directory):\n",
        "      filename = os.fsdecode(file)\n",
        "      name = \" \".join(filename.split('_')[:2]).lower()\n",
        "      name = name_mapping[name] if name in name_mapping else name\n",
        "      csv = pd.read_csv(formatted_string + filename + '/gw.csv', encoding = \"UTF-8\")\n",
        "      csv = csv[csv['round'] == ROUND]\n",
        "      csv = csv[fields]\n",
        "      csv = csv.astype('float')\n",
        "      players_data[name] = csv\n",
        "  \n",
        "  players_data = { name : df.drop_duplicates(subset=['round'], keep='last') for (name,df) in players_data.items() if len(df) > 0}\n",
        "\n",
        "  gameweek_data = {}\n",
        "  for name in players_data:\n",
        "    position = int(positions_and_teams[name][0])\n",
        "    team = int(positions_and_teams[name][1])\n",
        "    value = float(players_data[name]['value'])\n",
        "    minutes = float(players_data[name]['minutes'])\n",
        "    red_cards = float(players_data[name]['red_cards'])\n",
        "    yellow_cards = float(players_data[name]['yellow_cards'])\n",
        "    total_points = float(players_data[name]['total_points'])\n",
        "    data = {'team' : team, 'position' : position, 'value': value, 'total_points' : total_points,\n",
        "            'minutes' : minutes, 'yellow_cards' : yellow_cards, 'red_cards' : red_cards}\n",
        "    gameweek_data[name] = data\n",
        "\n",
        "  return gameweek_data\n",
        "\n",
        "\n",
        "class PlayerDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, players_data, batch_size, embedding_dim):\n",
        "    self.batch_size = batch_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    all_data = pd.concat([players_data[name] for name in players_data])\n",
        "    all_features = all_data.drop(['total_points'], axis=1).to_numpy()\n",
        "    all_points = all_data.drop(all_data.columns.difference(['total_points']), axis=1).to_numpy()\n",
        "\n",
        "    \"\"\"Apparently no need to scale points since MSE is robust to scaling?\"\"\"\n",
        "    feature_scaler = preprocessing.RobustScaler()\n",
        "    scaled_features = feature_scaler.fit_transform(all_features)\n",
        "\n",
        "    self.data = {}\n",
        "    training_data = []\n",
        "    end = 0\n",
        "\n",
        "    # Save each player's history and points, and add it to training set. \n",
        "    # Also save entire player's history for prediction later on\n",
        "    for name in players_data:\n",
        "      history_length = len(players_data[name])\n",
        "\n",
        "      for length in range(history_length - 1): # -1 because we have no prediction for the last point\n",
        "        history = torch.Tensor(scaled_features[end : end + 1 + length, :])\n",
        "        points = all_points[end + length + 1]\n",
        "        training_data.append((history, points))\n",
        "\n",
        "      new_end = end + history_length\n",
        "      self.data[name] = torch.Tensor(scaled_features[end : new_end, :])\n",
        "      end = new_end\n",
        "\n",
        "    # Create the training batches\n",
        "    random.shuffle(training_data)\n",
        "    num_batches = len(training_data) // self.batch_size\n",
        "    batches = [(k * self.batch_size, (k + 1) * self.batch_size) for k in range(num_batches)]\n",
        "    batches.append((num_batches * self.batch_size, len(training_data)))\n",
        "\n",
        "    self.batched_data = []\n",
        "    for (start, end) in batches:\n",
        "      if start != end:\n",
        "        lengths = [len(features) for (features, _) in training_data[start : end]]\n",
        "        three_d = torch.zeros((max(lengths), end - start, self.embedding_dim))\n",
        "\n",
        "        total_points = []\n",
        "        for index in range(start, end):\n",
        "          features, points = training_data[index]\n",
        "          three_d[: features.shape[0], index - start, : features.shape[1]] = features\n",
        "          total_points.append(points)\n",
        "\n",
        "        self.batched_data.append((three_d, torch.FloatTensor(lengths), torch.FloatTensor(total_points)))\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.batched_data)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.batched_data[index]\n",
        "    \n",
        "  def player_data(self, name):\n",
        "    return self.data[name]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}